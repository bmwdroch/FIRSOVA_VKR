# 2.3. Оценка качества моделей и работа с несбалансированными данными

Одним из ключевых аспектов прогнозирования оттока клиентов является правильная оценка качества моделей. В этой задаче особенно важно выбрать адекватные метрики, поскольку данные часто бывают несбалансированными: обычно доля клиентов, прекративших пользоваться услугами компании (положительный класс), значительно меньше доли оставшихся клиентов (отрицательный класс). В данном разделе рассматриваются методы оценки качества классификации и подходы к решению проблемы несбалансированности данных.

## 2.3.1. Метрики оценки качества классификации

При оценке моделей бинарной классификации для задачи прогнозирования оттока используется ряд специфических метрик, каждая из которых характеризует определенный аспект производительности модели.

### Матрица ошибок (Confusion Matrix)

Матрица ошибок является основой для расчета большинства метрик классификации и представляет собой таблицу, показывающую соотношение между предсказанными и фактическими классами:

| | Предсказано: Не уйдет (0) | Предсказано: Уйдет (1) |
|-|---------------------------|------------------------|
| **Фактически: Не уйдет (0)** | True Negative (TN) | False Positive (FP) |
| **Фактически: Уйдет (1)** | False Negative (FN) | True Positive (TP) |

где:
- **True Positive (TP)** — клиенты, правильно предсказанные как "уйдут"
- **True Negative (TN)** — клиенты, правильно предсказанные как "не уйдут"
- **False Positive (FP)** — клиенты, ошибочно предсказанные как "уйдут" (ошибка I рода)
- **False Negative (FN)** — клиенты, ошибочно предсказанные как "не уйдут" (ошибка II рода)

![Матрица ошибок](../../images/theory/confusion_matrix.png)

*Рисунок 2.3.1 - Схематическое представление матрицы ошибок для задачи прогнозирования оттока*

### Accuracy, Precision, Recall и F1-score

**Accuracy (Точность)** — доля правильных предсказаний среди всех предсказаний:

$$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$$

Несмотря на интуитивную понятность, Accuracy не является лучшей метрикой для несбалансированных данных, поскольку модель может достигать высокой точности, просто предсказывая преобладающий класс.

**Precision (Точность в узком смысле)** — доля правильных предсказаний положительного класса среди всех объектов, отнесенных к положительному классу:

$$Precision = \frac{TP}{TP + FP}$$

Показывает, какой процент клиентов, предсказанных как "уйдут", действительно уйдут. Высокая точность важна, когда стоимость программ удержания высока.

**Recall (Полнота)** — доля правильных предсказаний положительного класса среди всех объектов положительного класса:

$$Recall = \frac{TP}{TP + FN}$$

Показывает, какой процент от всех клиентов, которые на самом деле уйдут, модель сможет выявить. Высокая полнота важна, когда упущение потенциально уходящих клиентов дорого обходится компании.

**F1-score** — гармоническое среднее между Precision и Recall:

$$F1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall} = \frac{2TP}{2TP + FP + FN}$$

F1-score является хорошим балансом между Precision и Recall и часто используется как основная метрика для несбалансированных данных, когда необходимо учитывать оба аспекта.

### ROC-кривая и AUC

**ROC-кривая (Receiver Operating Characteristic curve)** — график, показывающий соотношение между True Positive Rate (TPR, также известный как Recall) и False Positive Rate (FPR) при различных пороговых значениях классификации:

$$TPR = Recall = \frac{TP}{TP + FN}$$

$$FPR = \frac{FP}{FP + TN}$$

ROC-кривая позволяет визуально оценить, насколько хорошо модель разделяет классы, а также выбрать оптимальный порог классификации в зависимости от бизнес-требований.

**AUC (Area Under the ROC Curve)** — площадь под ROC-кривой, которая количественно характеризует качество модели:
- AUC = 0.5: классификация не лучше случайной
- 0.5 < AUC < 0.7: удовлетворительная классификация
- 0.7 < AUC < 0.8: хорошая классификация
- 0.8 < AUC < 0.9: очень хорошая классификация
- 0.9 < AUC < 1.0: отличная классификация

AUC не зависит от порога классификации, что делает ее удобной метрикой для сравнения различных моделей.

![ROC-кривая](../../images/references/optimized_roc_curves.png)

*Рисунок 2.3.2 - Примеры ROC-кривых для различных моделей прогнозирования оттока*

### Precision-Recall кривая

**Precision-Recall кривая** — график зависимости Precision от Recall при различных пороговых значениях. Это особенно полезная визуализация для несбалансированных данных, поскольку она фокусируется только на производительности модели для положительного класса (в данном случае, клиентов, которые уйдут).

**PR AUC (Area Under the Precision-Recall Curve)** — площадь под Precision-Recall кривой, которая, подобно ROC AUC, количественно характеризует качество модели, но с фокусом на положительный класс.

Precision-Recall кривая предпочтительнее ROC-кривой при сильной несбалансированности классов, так как ROC-кривая может давать излишне оптимистичную оценку из-за большого количества True Negative.

![Precision-Recall кривая](../../images/references/optimized_precision_recall_curves.png)

*Рисунок 2.3.3 - Precision-Recall кривые для различных моделей прогнозирования оттока*

### Бизнес-ориентированные метрики

Помимо стандартных метрик машинного обучения, при оценке моделей прогнозирования оттока клиентов полезно использовать бизнес-ориентированные метрики:

**Lift** — показывает, насколько эффективнее таргетирование клиентов с помощью модели по сравнению со случайным выбором:

$$Lift@k\% = \frac{\text{Доля ушедших среди top k\% клиентов по прогнозу модели}}{\text{Средняя доля ушедших клиентов}}$$

**Cumulative Gains** — кумулятивный график, показывающий процент ушедших клиентов, которых можно было бы охватить, таргетируя определенный процент всех клиентов, отсортированных по предсказанной вероятности ухода.

**Expected Value** — ожидаемая финансовая выгода от использования модели, рассчитываемая на основе стоимости удержания клиента, ценности клиента и вероятности успешного удержания.

## 2.3.2. Проблема несбалансированных данных в задачах прогнозирования оттока

Несбалансированность данных является типичной проблемой при прогнозировании оттока клиентов: обычно доля ушедших клиентов составляет от 5% до 25% всей клиентской базы. Эта несбалансированность создает ряд проблем:

1. **Смещение модели в сторону большинства** — алгоритмы машинного обучения стремятся минимизировать общую ошибку, что приводит к предпочтению преобладающего класса.

2. **Вводящие в заблуждение метрики** — некоторые метрики (например, Accuracy) могут показывать высокие значения даже при плохом распознавании миноритарного класса.

3. **Недостаточное обучение на миноритарном классе** — модель получает меньше информации о редком классе, что затрудняет формирование обобщающих правил.

![Несбалансированность данных](../../images/references/target_distribution.png)

*Рисунок 2.3.4 - Распределение целевой переменной, демонстрирующее несбалансированность данных*

## 2.3.3. Методы решения проблемы несбалансированности

Существует несколько основных подходов к решению проблемы несбалансированных данных при прогнозировании оттока клиентов:

### Методы ресэмплинга

**Oversampling (Увеличение выборки миноритарного класса)**:
- **Случайное копирование** — простое дублирование объектов миноритарного класса
- **SMOTE (Synthetic Minority Over-sampling Technique)** — генерация синтетических примеров миноритарного класса путем интерполяции между существующими объектами
- **ADASYN (Adaptive Synthetic Sampling)** — улучшенная версия SMOTE, уделяющая больше внимания сложным для классификации объектам
- **BorderlineSMOTE** — фокусируется на границах между классами

**Undersampling (Уменьшение выборки мажоритарного класса)**:
- **Случайный отбор** — случайное удаление объектов мажоритарного класса
- **Tomek Links** — удаление объектов мажоритарного класса, формирующих "связи Томека"
- **NearMiss** — выбор объектов мажоритарного класса, ближайших к объектам миноритарного класса
- **Edited Nearest Neighbors** — удаление объектов, неправильно классифицированных k ближайшими соседями

**Гибридные методы**:
- **SMOTEENN** — комбинация SMOTE и Edited Nearest Neighbors
- **SMOTETomek** — комбинация SMOTE и Tomek Links

![Методы ресэмплинга](../../images/theory/resampling_methods.png)

*Рисунок 2.3.5 - Схематическое представление различных методов ресэмплинга*

### Настройка порога классификации

Стандартный порог классификации 0.5 часто не оптимален для несбалансированных данных. Альтернативные подходы:

- **Оптимизация порога на основе бизнес-метрик** — выбор порога, максимизирующего бизнес-ценность модели
- **Оптимизация по F1-score** — выбор порога, максимизирующего F1-score на валидационной выборке
- **Оптимизация по G-mean** — выбор порога, максимизирующего геометрическое среднее между чувствительностью и специфичностью
- **Анализ ROC-кривой и точки Youden** — выбор порога, соответствующего максимальному значению J = TPR - FPR

### Взвешивание классов

Взвешивание классов — подход, при котором объектам разных классов присваиваются различные веса в функции потерь:

$$Weight_{class} = \frac{N_{samples}}{N_{classes} \times N_{samples,class}}$$

Это позволяет алгоритму уделять больше внимания миноритарному классу без изменения исходных данных. Большинство современных алгоритмов (логистическая регрессия, случайный лес, XGBoost) поддерживают параметр class_weight или его аналоги.

### Специализированные алгоритмы

Некоторые алгоритмы лучше справляются с несбалансированными данными:

- **EasyEnsemble** — создание нескольких сбалансированных подвыборок и обучение отдельного классификатора на каждой
- **BalancedRandomForestClassifier** — случайный лес с балансировкой классов при создании деревьев
- **RUSBoost** — алгоритм бустинга, использующий случайный undersampling перед обучением каждого базового классификатора
- **SMOTE-Boost** — алгоритм бустинга, использующий SMOTE перед обучением каждого базового классификатора

### Выбор метрик

Правильный выбор метрик оценки также является частью решения проблемы несбалансированности:

- **F1-score, F2-score** — придает большее значение полноте, что может быть важно, когда критично не пропустить уходящих клиентов
- **Precision-Recall AUC** — фокусируется на производительности модели для положительного класса
- **G-mean** — геометрическое среднее между чувствительностью и специфичностью
- **Matthews Correlation Coefficient (MCC)** — учитывает все элементы матрицы ошибок

## Выбор оптимального подхода для задачи прогнозирования оттока

Для эффективного решения проблемы несбалансированности данных при прогнозировании оттока клиентов обычно применяется комбинация различных методов:

1. **Первичный анализ данных** — определение степени несбалансированности и особенностей распределения классов

2. **Выбор адекватных метрик** — использование F1-score, Precision-Recall AUC и бизнес-ориентированных метрик вместо Accuracy

3. **Применение техник ресэмплинга** — SMOTE часто используется из-за его эффективности и простоты реализации

4. **Настройка моделей с учетом несбалансированности** — использование весов классов и специализированных алгоритмов

5. **Оптимизация порога классификации** — выбор порога, оптимального с точки зрения бизнес-задачи

6. **Проверка эффективности** — тщательное тестирование модели на независимой выборке с использованием адекватных метрик

Конкретный набор методов зависит от степени несбалансированности данных, размера выборки, особенностей предметной области и бизнес-требований к модели прогнозирования оттока клиентов. 